from fastapi import FastAPI
from pydantic import BaseModel
from fastapi.middleware.cors import CORSMiddleware
from transformers import AutoTokenizer, AutoModelForCausalLM
import firebase_admin
from firebase_admin import credentials, firestore
import time

# ğŸ”¸ Firebase ì´ˆê¸°í™”
cred = credentials.Certificate("serviceAccountKey.json")  # Firebase ì½˜ì†”ì—ì„œ ë°œê¸‰
firebase_admin.initialize_app(cred)
db = firestore.client()

# ğŸ”¸ ëª¨ë¸ ë¡œë”©
MODEL_PATH = "/workspace/2.AIí•™ìŠµëª¨ë¸íŒŒì¼/1. ì§ˆì˜ì‘ë‹µ/nia15-polyglot-5.8b-koalpaca-v1.1b-qna-best"
tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)
model = AutoModelForCausalLM.from_pretrained(
    MODEL_PATH, device_map="auto", dtype="auto"
)

app = FastAPI()

# CORS í—ˆìš©
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)

class Query(BaseModel):
    message: str

@app.post("/chat")
def chat(query: Query):
    # ğŸ”¸ ì‚¬ìš©ì ì…ë ¥ ì €ì¥
    db.collection("chat_history").add({
        "role": "user",
        "message": query.message,
        "timestamp": firestore.SERVER_TIMESTAMP
    })

    # ğŸ”¸ ëª¨ë¸ ì¶”ë¡ 
    inputs = tokenizer(query.message, return_tensors="pt").to("cuda")
    if "token_type_ids" in inputs:
        del inputs["token_type_ids"]

    outputs = model.generate(
        **inputs,
        max_new_tokens=300,
        temperature=0.7,
        top_p=0.9,
        repetition_penalty=1.2,
        pad_token_id=tokenizer.eos_token_id
    )
    answer = tokenizer.decode(outputs[0], skip_special_tokens=True)

    # ğŸ”¸ ëª¨ë¸ ë‹µë³€ ì €ì¥
    db.collection("chat_history").add({
        "role": "bot",
        "message": answer,
        "timestamp": firestore.SERVER_TIMESTAMP
    })

    return {"answer": answer}

@app.get("/history")
def history():
    docs = db.collection("chat_history").order_by("timestamp").stream()
    return [{"role": d.to_dict()["role"], "message": d.to_dict()["message"]} for d in docs]
